# -*- coding: utf-8 -*-
"""Data Pipelines with Redis project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IIZBuSP97Lt02SyCrxX87Ksd6vjUhrzh
"""

# importing redis drive
!pip install redis


# Import required libraries
import pandas as pd
import psycopg2
import redis
from io import BytesIO


# Redis Cloud Instance Information
redis_host = 'redis-17569.c275.us-east-1-4.ec2.cloud.redislabs.com'
redis_port = 17569
redis_password = 'Minimum7467!' 


# Postgres Database Information
pg_host = "35.233.221.160"
pg_database = "mydbs1"
pg_user = "studentj"
pg_password = "minimum7467!"


# Redis Client Object
r = redis.Redis(
  host= redis_host,
  port= redis_port,
  password=redis_password)



# Define function to extract data from Redis and return a Pandas DataFrame
def extract_data():
    # check if the data is cached in Redis
    if r.exists('customer_call_logs'):
        return pd.read_pickle(r.get('customer_call_logs'))
    # extract data from CSV file
    df = pd.read_csv('customer_call_logs.csv')
    # cache data in Redis
    with BytesIO() as f:
        df.to_pickle(f)
        r.set('customer_call_logs', f.getvalue())
    return df


def transform_data():
  # Retrieve data from Redis cache
  data = pd.read_json(redis_client.get('customer_call_logs'))
  # clean data
  transformed_df = data.dropna()
  # structure data
  transformed_df['call_duration'] = transformed_df['call_duration'].apply(lambda x: int(x.split(':')[0]) * 60 + int(x.split(':')[1]))
  transformed_df['call_destination'] = transformed_df['call_destination'].apply(lambda x: '+1' + x.replace('-', ''))
  # format data
  transformed_df['call_date'] = pd.to_datetime(transformed_df['call_date'], format='%d-%m-%Y')
  return transformed_df


 # Define function to load data into Postgres
def load_data(transformed_data):
  # Connect to Postgres database
  conn = psycopg2.connect(host=pg_host, database=pg_database, user=pg_user, password=pg_password)

  # Create a cursor object
  cur = conn.cursor()

  # Create a table to store the data
  cur.execute('''CREATE TABLE IF NOT EXISTS customer_call_logs (
                 customer_id INT,
                 call_cost_usd FLOAT,
                 call_destination VARCHAR,
                 call_date TIMESTAMP,
                 call_duration_min FLOAT
                 )''')

  # Insert the transformed data into the database
  for i, row in transformed_data.iterrows():
    cur.execute(f"INSERT INTO customer_call_logs (customer_id, call_cost_usd, call_destination, call_date, call_duration_min) VALUES ({row['customer_id']}, {row['call_cost_usd']}, '{row['call_destination']}', '{row['call_date']}', {row['call_duration_min']})")

    # Commit the changes
    conn.commit()

    # Close the cursor and connection
    cur.close()
    conn.close() 


def data_pipeline():
  # Data pipeline function
  extract_data()
  transformed_data = transform_data()
  load_data(transformed_data)

if __name__ == '__main__':
  # Run the data pipeline function
  data_pipeline()